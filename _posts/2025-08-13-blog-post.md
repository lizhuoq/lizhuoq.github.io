---
title: 'CatBoostRegressor自定义损失函数和评价指标'
date: 2025-08-13
permalink: /posts/2025/08/blog-post-1/
tags:
  - 机器学习
  - 结构化数据
  - 回归任务
  - Boosting算法
---

CatBoostRegressor是一个强大的梯度提升树模型，广泛应用于结构化数据的回归任务。本文将介绍如何在CatBoost中自定义损失函数和评价指标，以满足特定的业务需求。CatBoostRegressor支持多种损失函数和评价指标如下图所示，但有时我们需要根据实际情况进行调整。  

![loss](2025-08-13_files/2025-08-13_1.png)

对于Root Mean Squared Percentage Error (RMSPE)损失函数，在CatBoostRegressor中并没有实现。MSPE的计算公式为：

$$\text{RMSPE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} \left( \frac{y_i - \hat{y}_i}{y_i} \right)^2}$$


rmspe和rmse的区别在于，rmspe是相对误差的平方根，而rmse是绝对误差的平方根，rmspe考虑了目标值的比例关系。

为了在CatBoost中实现自定义损失函数和评价指标，我们需要定义一个类，并实现相应的方法。
```python
class UserDefinedObjective(object):
    def calc_ders_range(self, approxes, targets, weights):
        # approxes、targets、weights 是浮点数的可索引容器
        # （只实现了 __len__ 和 __getitem__ 方法的容器）。
        # weights 参数可能为 None。
        #
        # 为了理解这些参数的含义，可以假设当前正在处理数据集的一个子集。
        # approxes 包含该子集的当前预测值，
        # targets 包含数据集中你提供的真实目标值。
        #
        # 该函数应返回一个由若干对 (-der1, -der2) 组成的列表，
        # 其中 der1 是损失函数对预测值的一阶导数，
        # der2 是二阶导数。
        pass

class UserDefinedMultiClassObjective(object):
    def calc_ders_multi(self, approxes, target, weight):
        # approxes —— 浮点数的可索引容器，包含单个样本在每个类别上的预测值
        # target —— 包含单个样本的真实类别标签
        # weight —— 样本的权重
        #
        # 该函数应返回一个元组 (-der1, -der2)，其中：
        # - der1 是一类列表对象，表示损失函数对每个类别预测值的一阶导数；
        # - der2 是一个矩阵，表示二阶导数。
        pass

```

## 实现RMSPE损失函数
CatBoost官方文档中给出了一个自定义损失函数的示例，下面是一个实现RMSE损失函数的示例代码：

```python
class RmseObjective(object):
    def calc_ders_range(self, approxes, targets, weights):
        assert len(approxes) == len(targets)
        if weights is not None:
            assert len(weights) == len(approxes)

        result = []
        for index in range(len(targets)):
            der1 = targets[index] - approxes[index]
            der2 = -1

            if weights is not None:
                der1 *= weights[index]
                der2 *= weights[index]

            result.append((der1, der2))
        return result

```  

最主要的就是要计算出损失函数的一阶导数和二阶导数。CatBoost会使用这些导数来更新模型参数。下面给出了RMSE一阶导数和二阶导数的计算公式：

$$\text{der1} = y_i - \hat{y}_i$$  


$$\text{der2} = -1$$

因此我们要首先计算RMSPE的一阶导数和二阶导数。RMSPE的一阶导数和二阶导数的计算公式如下：

$$\text{der1} = \frac{y_i - \hat{y}_i}{y_i^2}$$  


$$\text{der2} = -\frac{1}{y_i^2}$$  

通过比较RMSE和RMSPE的导数，我们可以发现RMSPE的一阶导数和二阶导数与RMSE的导数分子相同，但分母不同。RMSE的分母是1，而RMSPE的分母是$y_i^2$。因此，我们可以将RMSPE的一阶导数和二阶导数的计算公式直接应用到CatBoost中。

```python
class RmspeObjective(object):
    def calc_ders_range(self, approxes, targets, weights):
        assert len(approxes) == len(targets)
        if weights is not None:
            assert len(weights) == len(approxes)

        result = []
        for index in range(len(targets)):
            der1 = (targets[index] - approxes[index]) / (targets[index] ** 2)
            der2 = -1 / (targets[index] ** 2)

            if weights is not None:
                der1 *= weights[index]
                der2 *= weights[index]

            result.append((der1, der2))
        return result
```  

## 定义RMSPE评价指标
接下来，我们需要定义一个自定义评价指标。CatBoost官方实现了RMSE评价指标，我们可以参考其实现来定义RMSPE评价指标。评价指标可以用于模型训练监控验证集的性能，并在训练过程中进行早停，避浪费计算资源和过拟合。

```python
class RmseMetric(object):
    def get_final_error(self, error, weight):
        return np.sqrt(error / (weight + 1e-38))

    def is_max_optimal(self):
        return False

    def evaluate(self, approxes, target, weight):
        assert len(approxes) == 1
        assert len(target) == len(approxes[0])

        approx = approxes[0]

        error_sum = 0.0
        weight_sum = 0.0

        for i in range(len(approx)):
            w = 1.0 if weight is None else weight[i]
            weight_sum += w
            error_sum += w * ((approx[i] - target[i])**2)

        return error_sum, weight_sum
```  

从RMSE评价指标的实现中，我们可以看到它的`evaluate`方法计算了预测值和真实值之间的误差平方和，并返回误差和权重的总和。我们可以将其修改为RMSPE评价指标。

```python
class MspeMetric(object):
    def get_final_error(self, error, weight):
        return np.sqrt(error / (weight + 1e-38))

    def is_max_optimal(self):
        return False

    def evaluate(self, approxes, target, weight):
        assert len(approxes) == 1
        assert len(target) == len(approxes[0])

        approx = approxes[0]

        error_sum = 0.0
        weight_sum = 0.0

        for i in range(len(approx)):
            w = 1.0 if weight is None else weight[i]
            weight_sum += w
            error_sum += w * ((approx[i] - target[i])**2 / (target[i] ** 2))

        return error_sum, weight_sum
```  

## 实验结果  
在根据历史发电功率数据和对应时段气象预测数据集，实现未来2个月每天15分钟分辨率（共 96 个时间点）的新能源场站发电功率预测进行实验。

### RMSPE  
```python
model = CatBoostRegressor(
    iterations=9000,           # 延长迭代次数
    learning_rate=0.02,        # 更慢收敛
    depth=7,                   # 降低深度，延长训练周期
    l2_leaf_reg=6,             # 略加正则化
    bagging_temperature=1.0,   # 保持多样性
    random_strength=1.0,       
    border_count=254,
    boosting_type='Plain',
    loss_function=MspeObjective(),
    eval_metric=MspeMetric(),
    random_seed=42,
    od_type='Iter',
    od_wait=300,               # 延长早停等待，保证充分训练
    verbose=200
)


submission = TrainML(model, df_train, df_test)
submission.to_csv('output1.csv', index=False)
```
- 实验日志   

```plaintext
(19550, 141) (5664, 141)
time          0
real_power    0
hour_sin      0
hour_cos      0
month_sin     0
             ..
wd_cos_-1     0
wd_cos_1      1
wd_cos_2      2
wd_cos_3      3
wd_cos_4      4
Length: 141, dtype: int64
time             0
predict_power    0
hour_sin         0
hour_cos         0
month_sin        0
                ..
wd_cos_-1        1
wd_cos_1         0
wd_cos_2         0
wd_cos_3         0
wd_cos_4         0
Length: 141, dtype: int64
Training Folds:   0%|          | 0/5 [00:00<?, ?it/s]
0:	learn: 0.9982101	test: 0.9980178	best: 0.9980178 (0)	total: 1.88s	remaining: 4h 41m 55s
200:	learn: 0.7252630	test: 0.6949048	best: 0.6949048 (200)	total: 10.5s	remaining: 7m 40s
400:	learn: 0.6341535	test: 0.6062397	best: 0.6062397 (400)	total: 18.9s	remaining: 6m 45s
600:	learn: 0.5914456	test: 0.5655392	best: 0.5655392 (600)	total: 28.1s	remaining: 6m 32s
800:	learn: 0.5625317	test: 0.5404388	best: 0.5404388 (800)	total: 36.6s	remaining: 6m 14s
1000:	learn: 0.5435274	test: 0.5246513	best: 0.5246513 (1000)	total: 45.1s	remaining: 6m
1200:	learn: 0.5308105	test: 0.5149253	best: 0.5149253 (1200)	total: 53.4s	remaining: 5m 47s
1400:	learn: 0.5217064	test: 0.5085152	best: 0.5085152 (1400)	total: 1m 2s	remaining: 5m 38s
1600:	learn: 0.5140563	test: 0.5036787	best: 0.5036787 (1600)	total: 1m 10s	remaining: 5m 27s
1800:	learn: 0.5076437	test: 0.4995717	best: 0.4995717 (1800)	total: 1m 19s	remaining: 5m 16s
2000:	learn: 0.5022554	test: 0.4964550	best: 0.4964550 (2000)	total: 1m 27s	remaining: 5m 7s
2200:	learn: 0.4978501	test: 0.4939464	best: 0.4939464 (2200)	total: 1m 36s	remaining: 4m 57s
2400:	learn: 0.4942087	test: 0.4919081	best: 0.4919081 (2400)	total: 1m 44s	remaining: 4m 47s
2600:	learn: 0.4906786	test: 0.4898442	best: 0.4898442 (2600)	total: 1m 52s	remaining: 4m 37s
2800:	learn: 0.4875415	test: 0.4881500	best: 0.4881500 (2800)	total: 2m 1s	remaining: 4m 29s
3000:	learn: 0.4847007	test: 0.4865416	best: 0.4865416 (3000)	total: 2m 9s	remaining: 4m 19s
3200:	learn: 0.4822172	test: 0.4849645	best: 0.4849639 (3199)	total: 2m 17s	remaining: 4m 9s
3400:	learn: 0.4798140	test: 0.4833645	best: 0.4833645 (3400)	total: 2m 25s	remaining: 4m
3600:	learn: 0.4775931	test: 0.4822117	best: 0.4822117 (3600)	total: 2m 34s	remaining: 3m 51s
3800:	learn: 0.4755598	test: 0.4813307	best: 0.4813256 (3794)	total: 2m 42s	remaining: 3m 42s
4000:	learn: 0.4736608	test: 0.4805722	best: 0.4805602 (3998)	total: 2m 50s	remaining: 3m 33s
4200:	learn: 0.4718411	test: 0.4798631	best: 0.4798631 (4200)	total: 2m 58s	remaining: 3m 24s
4400:	learn: 0.4700072	test: 0.4791095	best: 0.4791091 (4398)	total: 3m 7s	remaining: 3m 15s
4600:	learn: 0.4682309	test: 0.4786074	best: 0.4786074 (4600)	total: 3m 15s	remaining: 3m 6s
4800:	learn: 0.4665778	test: 0.4780648	best: 0.4780648 (4800)	total: 3m 23s	remaining: 2m 58s
5000:	learn: 0.4649941	test: 0.4775728	best: 0.4775696 (4999)	total: 3m 31s	remaining: 2m 49s
5200:	learn: 0.4634863	test: 0.4771959	best: 0.4771959 (5200)	total: 3m 40s	remaining: 2m 40s
5400:	learn: 0.4620279	test: 0.4767723	best: 0.4767723 (5400)	total: 3m 48s	remaining: 2m 32s
5600:	learn: 0.4606138	test: 0.4764074	best: 0.4763944 (5594)	total: 3m 56s	remaining: 2m 23s
5800:	learn: 0.4593079	test: 0.4762211	best: 0.4762088 (5791)	total: 4m 4s	remaining: 2m 14s
6000:	learn: 0.4580079	test: 0.4761048	best: 0.4761017 (5968)	total: 4m 13s	remaining: 2m 6s
6200:	learn: 0.4567544	test: 0.4759764	best: 0.4759764 (6200)	total: 4m 21s	remaining: 1m 58s
6400:	learn: 0.4555192	test: 0.4758999	best: 0.4758807 (6386)	total: 4m 29s	remaining: 1m 49s
6600:	learn: 0.4543637	test: 0.4757631	best: 0.4757549 (6597)	total: 4m 37s	remaining: 1m 40s
6800:	learn: 0.4532706	test: 0.4756103	best: 0.4756015 (6795)	total: 4m 46s	remaining: 1m 32s
7000:	learn: 0.4520990	test: 0.4755322	best: 0.4755127 (6973)	total: 4m 54s	remaining: 1m 24s
7200:	learn: 0.4510410	test: 0.4754414	best: 0.4754367 (7197)	total: 5m 2s	remaining: 1m 15s
7400:	learn: 0.4500855	test: 0.4752374	best: 0.4752275 (7389)	total: 5m 10s	remaining: 1m 7s
7600:	learn: 0.4491055	test: 0.4750725	best: 0.4750725 (7600)	total: 5m 19s	remaining: 58.8s
7800:	learn: 0.4482135	test: 0.4749056	best: 0.4749056 (7800)	total: 5m 27s	remaining: 50.3s
8000:	learn: 0.4474322	test: 0.4747393	best: 0.4747393 (8000)	total: 5m 35s	remaining: 41.9s
8200:	learn: 0.4467335	test: 0.4746560	best: 0.4746499 (8197)	total: 5m 43s	remaining: 33.5s
8400:	learn: 0.4461039	test: 0.4746081	best: 0.4745854 (8351)	total: 5m 52s	remaining: 25.1s
8600:	learn: 0.4455976	test: 0.4744966	best: 0.4744944 (8593)	total: 6m	remaining: 16.7s
8800:	learn: 0.4451555	test: 0.4743606	best: 0.4743606 (8800)	total: 6m 8s	remaining: 8.33s
8999:	learn: 0.4447384	test: 0.4742803	best: 0.4742770 (8992)	total: 6m 16s	remaining: 0us

bestTest = 0.4742769507
bestIteration = 8992

Shrink model to first 8993 iterations.
Training Folds:  20%|██        | 1/5 [06:20<25:21, 380.35s/it]
Fold 1 - Train RMSE: 0.4447, Validation RMSE: 0.4743
0:	learn: 0.9981107	test: 0.9985138	best: 0.9985138 (0)	total: 487ms	remaining: 1h 13m
200:	learn: 0.7150975	test: 0.7564048	best: 0.7564048 (200)	total: 9.38s	remaining: 6m 50s
400:	learn: 0.6216807	test: 0.6649620	best: 0.6649620 (400)	total: 17.7s	remaining: 6m 20s
600:	learn: 0.5794504	test: 0.6215374	best: 0.6215374 (600)	total: 26.3s	remaining: 6m 6s
800:	learn: 0.5537605	test: 0.5962245	best: 0.5962245 (800)	total: 35.1s	remaining: 5m 59s
1000:	learn: 0.5358001	test: 0.5794203	best: 0.5794203 (1000)	total: 43.7s	remaining: 5m 49s
1200:	learn: 0.5246261	test: 0.5703857	best: 0.5703857 (1200)	total: 52.3s	remaining: 5m 39s
1400:	learn: 0.5147885	test: 0.5631551	best: 0.5631551 (1400)	total: 1m	remaining: 5m 29s
1600:	learn: 0.5063778	test: 0.5572792	best: 0.5572792 (1600)	total: 1m 9s	remaining: 5m 22s
1800:	learn: 0.4992426	test: 0.5526270	best: 0.5526270 (1800)	total: 1m 18s	remaining: 5m 12s
2000:	learn: 0.4931703	test: 0.5493830	best: 0.5493830 (2000)	total: 1m 26s	remaining: 5m 1s
2200:	learn: 0.4879389	test: 0.5464928	best: 0.5464928 (2200)	total: 1m 34s	remaining: 4m 52s
2400:	learn: 0.4830984	test: 0.5438060	best: 0.5438060 (2400)	total: 1m 43s	remaining: 4m 44s
2600:	learn: 0.4789749	test: 0.5418038	best: 0.5418038 (2600)	total: 1m 51s	remaining: 4m 35s
2800:	learn: 0.4753148	test: 0.5402579	best: 0.5402579 (2800)	total: 2m	remaining: 4m 26s
3000:	learn: 0.4720657	test: 0.5391697	best: 0.5391697 (3000)	total: 2m 8s	remaining: 4m 17s
3200:	learn: 0.4691481	test: 0.5382719	best: 0.5382688 (3199)	total: 2m 17s	remaining: 4m 9s
3400:	learn: 0.4664955	test: 0.5375295	best: 0.5375295 (3399)	total: 2m 26s	remaining: 4m
3600:	learn: 0.4639279	test: 0.5369001	best: 0.5369001 (3600)	total: 2m 34s	remaining: 3m 51s
3800:	learn: 0.4615574	test: 0.5363544	best: 0.5363544 (3800)	total: 2m 42s	remaining: 3m 42s
4000:	learn: 0.4592787	test: 0.5357306	best: 0.5357306 (4000)	total: 2m 51s	remaining: 3m 34s
4200:	learn: 0.4570181	test: 0.5350047	best: 0.5350047 (4200)	total: 3m	remaining: 3m 25s
4400:	learn: 0.4546849	test: 0.5342049	best: 0.5342049 (4400)	total: 3m 8s	remaining: 3m 16s
4600:	learn: 0.4523855	test: 0.5337550	best: 0.5337550 (4600)	total: 3m 16s	remaining: 3m 8s
4800:	learn: 0.4503832	test: 0.5332769	best: 0.5332769 (4800)	total: 3m 25s	remaining: 2m 59s
5000:	learn: 0.4485450	test: 0.5328689	best: 0.5328498 (4994)	total: 3m 33s	remaining: 2m 50s
5200:	learn: 0.4469705	test: 0.5324894	best: 0.5324858 (5199)	total: 3m 41s	remaining: 2m 41s
5400:	learn: 0.4455256	test: 0.5321360	best: 0.5321360 (5400)	total: 3m 50s	remaining: 2m 33s
5600:	learn: 0.4442180	test: 0.5316855	best: 0.5316855 (5600)	total: 3m 58s	remaining: 2m 24s
5800:	learn: 0.4430417	test: 0.5313508	best: 0.5313424 (5799)	total: 4m 6s	remaining: 2m 16s
6000:	learn: 0.4419662	test: 0.5310253	best: 0.5310199 (5998)	total: 4m 15s	remaining: 2m 7s
6200:	learn: 0.4409142	test: 0.5307847	best: 0.5307846 (6194)	total: 4m 23s	remaining: 1m 59s
6400:	learn: 0.4400377	test: 0.5305765	best: 0.5305751 (6399)	total: 4m 31s	remaining: 1m 50s
6600:	learn: 0.4392117	test: 0.5303727	best: 0.5303651 (6597)	total: 4m 40s	remaining: 1m 41s
6800:	learn: 0.4384764	test: 0.5301826	best: 0.5301775 (6797)	total: 4m 48s	remaining: 1m 33s
7000:	learn: 0.4377639	test: 0.5299869	best: 0.5299670 (6985)	total: 4m 57s	remaining: 1m 24s
7200:	learn: 0.4370577	test: 0.5297869	best: 0.5297798 (7186)	total: 5m 5s	remaining: 1m 16s
7400:	learn: 0.4364626	test: 0.5295971	best: 0.5295961 (7399)	total: 5m 13s	remaining: 1m 7s
7600:	learn: 0.4358176	test: 0.5294412	best: 0.5294412 (7600)	total: 5m 21s	remaining: 59.2s
7800:	learn: 0.4351864	test: 0.5293245	best: 0.5293245 (7800)	total: 5m 30s	remaining: 50.8s
8000:	learn: 0.4346540	test: 0.5291614	best: 0.5291614 (8000)	total: 5m 38s	remaining: 42.3s
8200:	learn: 0.4341259	test: 0.5290094	best: 0.5290094 (8200)	total: 5m 46s	remaining: 33.8s
8400:	learn: 0.4334619	test: 0.5288515	best: 0.5288514 (8399)	total: 5m 54s	remaining: 25.3s
8600:	learn: 0.4328849	test: 0.5288210	best: 0.5287828 (8497)	total: 6m 3s	remaining: 16.9s
8800:	learn: 0.4322541	test: 0.5286498	best: 0.5286478 (8796)	total: 6m 11s	remaining: 8.4s
8999:	learn: 0.4317270	test: 0.5284883	best: 0.5284813 (8973)	total: 6m 19s	remaining: 0us

bestTest = 0.5284813459
bestIteration = 8973

Shrink model to first 8974 iterations.
Training Folds:  40%|████      | 2/5 [12:42<19:04, 381.40s/it]
Fold 2 - Train RMSE: 0.4318, Validation RMSE: 0.5285
0:	learn: 0.9985829	test: 0.9985291	best: 0.9985291 (0)	total: 673ms	remaining: 1h 40m 52s
200:	learn: 0.7219624	test: 0.7335064	best: 0.7335064 (200)	total: 9.15s	remaining: 6m 40s
400:	learn: 0.6294646	test: 0.6463150	best: 0.6463150 (400)	total: 18s	remaining: 6m 25s
600:	learn: 0.5845642	test: 0.6050398	best: 0.6050398 (600)	total: 26.5s	remaining: 6m 10s
800:	learn: 0.5578018	test: 0.5802514	best: 0.5802514 (800)	total: 34.9s	remaining: 5m 57s
1000:	learn: 0.5429246	test: 0.5664208	best: 0.5664208 (1000)	total: 43.9s	remaining: 5m 51s
1200:	learn: 0.5304812	test: 0.5535177	best: 0.5535177 (1200)	total: 52.5s	remaining: 5m 40s
1400:	learn: 0.5208142	test: 0.5440069	best: 0.5440069 (1400)	total: 1m	remaining: 5m 30s
1600:	learn: 0.5127465	test: 0.5354780	best: 0.5354780 (1600)	total: 1m 9s	remaining: 5m 21s
1800:	learn: 0.5059239	test: 0.5281041	best: 0.5281041 (1800)	total: 1m 18s	remaining: 5m 13s
2000:	learn: 0.5001116	test: 0.5218852	best: 0.5218852 (2000)	total: 1m 26s	remaining: 5m 3s
2200:	learn: 0.4953300	test: 0.5163660	best: 0.5163660 (2200)	total: 1m 35s	remaining: 4m 53s
2400:	learn: 0.4911659	test: 0.5118778	best: 0.5118778 (2400)	total: 1m 43s	remaining: 4m 43s
2600:	learn: 0.4875683	test: 0.5082434	best: 0.5082434 (2600)	total: 1m 52s	remaining: 4m 35s
2800:	learn: 0.4844610	test: 0.5051724	best: 0.5051724 (2800)	total: 2m	remaining: 4m 26s
3000:	learn: 0.4815632	test: 0.5019981	best: 0.5019981 (3000)	total: 2m 8s	remaining: 4m 17s
3200:	learn: 0.4789951	test: 0.4990418	best: 0.4990418 (3200)	total: 2m 16s	remaining: 4m 8s
3400:	learn: 0.4766193	test: 0.4966015	best: 0.4966015 (3400)	total: 2m 25s	remaining: 3m 59s
3600:	learn: 0.4744406	test: 0.4945778	best: 0.4945778 (3600)	total: 2m 34s	remaining: 3m 50s
3800:	learn: 0.4724023	test: 0.4927454	best: 0.4927454 (3800)	total: 2m 42s	remaining: 3m 41s
4000:	learn: 0.4704505	test: 0.4910741	best: 0.4910741 (4000)	total: 2m 50s	remaining: 3m 33s
4200:	learn: 0.4685723	test: 0.4895213	best: 0.4895213 (4200)	total: 2m 59s	remaining: 3m 25s
4400:	learn: 0.4668568	test: 0.4881208	best: 0.4881155 (4399)	total: 3m 7s	remaining: 3m 16s
4600:	learn: 0.4651109	test: 0.4869676	best: 0.4869622 (4599)	total: 3m 16s	remaining: 3m 7s
4800:	learn: 0.4633648	test: 0.4858594	best: 0.4858594 (4800)	total: 3m 24s	remaining: 2m 59s
5000:	learn: 0.4617493	test: 0.4847171	best: 0.4847171 (5000)	total: 3m 33s	remaining: 2m 50s
5200:	learn: 0.4602923	test: 0.4836034	best: 0.4836034 (5200)	total: 3m 41s	remaining: 2m 41s
5400:	learn: 0.4588806	test: 0.4825934	best: 0.4825934 (5400)	total: 3m 50s	remaining: 2m 33s
5600:	learn: 0.4574452	test: 0.4818266	best: 0.4818266 (5600)	total: 3m 58s	remaining: 2m 24s
5800:	learn: 0.4559652	test: 0.4810306	best: 0.4810306 (5800)	total: 4m 7s	remaining: 2m 16s
6000:	learn: 0.4545507	test: 0.4802676	best: 0.4802676 (6000)	total: 4m 15s	remaining: 2m 7s
6200:	learn: 0.4534057	test: 0.4795651	best: 0.4795585 (6199)	total: 4m 23s	remaining: 1m 59s
6400:	learn: 0.4523884	test: 0.4789661	best: 0.4789661 (6400)	total: 4m 32s	remaining: 1m 50s
6600:	learn: 0.4515024	test: 0.4784603	best: 0.4784603 (6600)	total: 4m 41s	remaining: 1m 42s
6800:	learn: 0.4506262	test: 0.4779366	best: 0.4779366 (6800)	total: 4m 49s	remaining: 1m 33s
7000:	learn: 0.4498587	test: 0.4774159	best: 0.4774159 (7000)	total: 4m 58s	remaining: 1m 25s
7200:	learn: 0.4492089	test: 0.4769370	best: 0.4769370 (7200)	total: 5m 6s	remaining: 1m 16s
7400:	learn: 0.4485144	test: 0.4764732	best: 0.4764732 (7400)	total: 5m 15s	remaining: 1m 8s
7600:	learn: 0.4478632	test: 0.4760578	best: 0.4760578 (7600)	total: 5m 23s	remaining: 59.5s
7800:	learn: 0.4472732	test: 0.4756850	best: 0.4756850 (7800)	total: 5m 31s	remaining: 51s
8000:	learn: 0.4466675	test: 0.4753789	best: 0.4753781 (7999)	total: 5m 40s	remaining: 42.5s
8200:	learn: 0.4460966	test: 0.4750361	best: 0.4750361 (8200)	total: 5m 48s	remaining: 34s
8400:	learn: 0.4455220	test: 0.4747711	best: 0.4747711 (8400)	total: 5m 56s	remaining: 25.5s
8600:	learn: 0.4449765	test: 0.4744575	best: 0.4744575 (8600)	total: 6m 5s	remaining: 16.9s
8800:	learn: 0.4445157	test: 0.4741898	best: 0.4741898 (8800)	total: 6m 13s	remaining: 8.45s
8999:	learn: 0.4440446	test: 0.4739086	best: 0.4739086 (8999)	total: 6m 22s	remaining: 0us

bestTest = 0.4739086406
bestIteration = 8999

Training Folds:  60%|██████    | 3/5 [19:07<12:45, 382.83s/it]
Fold 3 - Train RMSE: 0.4440, Validation RMSE: 0.4739
0:	learn: 0.9983573	test: 0.9983019	best: 0.9983019 (0)	total: 460ms	remaining: 1h 9m 3s
200:	learn: 0.7307851	test: 0.7133846	best: 0.7133846 (200)	total: 8.95s	remaining: 6m 31s
400:	learn: 0.6362208	test: 0.6246725	best: 0.6246725 (400)	total: 18s	remaining: 6m 26s
600:	learn: 0.5913420	test: 0.5861919	best: 0.5861919 (600)	total: 26.6s	remaining: 6m 11s
800:	learn: 0.5667922	test: 0.5679436	best: 0.5679436 (800)	total: 35.2s	remaining: 6m
1000:	learn: 0.5464303	test: 0.5566868	best: 0.5566868 (1000)	total: 43.8s	remaining: 5m 49s
1200:	learn: 0.5313673	test: 0.5513994	best: 0.5513994 (1200)	total: 52.9s	remaining: 5m 43s
1400:	learn: 0.5197846	test: 0.5491701	best: 0.5491513 (1398)	total: 1m 1s	remaining: 5m 33s
1600:	learn: 0.5101159	test: 0.5494826	best: 0.5490261 (1428)	total: 1m 10s	remaining: 5m 23s
Training Folds:  80%|████████  | 4/5 [20:23<04:21, 261.81s/it]
Stopped by overfitting detector  (300 iterations wait)

bestTest = 0.5490260741
bestIteration = 1428

Shrink model to first 1429 iterations.
Fold 4 - Train RMSE: 0.5183, Validation RMSE: 0.5490
0:	learn: 0.9977818	test: 0.9980270	best: 0.9980270 (0)	total: 465ms	remaining: 1h 9m 40s
200:	learn: 0.7136320	test: 0.7271006	best: 0.7271006 (200)	total: 9.41s	remaining: 6m 51s
400:	learn: 0.6293143	test: 0.6318850	best: 0.6318850 (400)	total: 18.1s	remaining: 6m 27s
600:	learn: 0.5908187	test: 0.5873180	best: 0.5873180 (600)	total: 26.7s	remaining: 6m 12s
800:	learn: 0.5675285	test: 0.5621087	best: 0.5621087 (800)	total: 35.6s	remaining: 6m 4s
1000:	learn: 0.5501808	test: 0.5432161	best: 0.5432161 (1000)	total: 44.8s	remaining: 5m 57s
1200:	learn: 0.5375891	test: 0.5307829	best: 0.5307829 (1200)	total: 53.6s	remaining: 5m 47s
1400:	learn: 0.5276682	test: 0.5221384	best: 0.5221384 (1400)	total: 1m 2s	remaining: 5m 38s
1600:	learn: 0.5189688	test: 0.5149592	best: 0.5149592 (1600)	total: 1m 11s	remaining: 5m 30s
1800:	learn: 0.5117895	test: 0.5093052	best: 0.5093052 (1800)	total: 1m 20s	remaining: 5m 20s
2000:	learn: 0.5057592	test: 0.5049703	best: 0.5049703 (2000)	total: 1m 28s	remaining: 5m 10s
2200:	learn: 0.5004766	test: 0.5016746	best: 0.5016746 (2200)	total: 1m 37s	remaining: 5m 1s
2400:	learn: 0.4958129	test: 0.4992381	best: 0.4992381 (2400)	total: 1m 46s	remaining: 4m 53s
2600:	learn: 0.4922085	test: 0.4972401	best: 0.4972401 (2600)	total: 1m 55s	remaining: 4m 43s
2800:	learn: 0.4888042	test: 0.4954639	best: 0.4954639 (2800)	total: 2m 3s	remaining: 4m 33s
3000:	learn: 0.4858477	test: 0.4938861	best: 0.4938861 (3000)	total: 2m 11s	remaining: 4m 23s
3200:	learn: 0.4832179	test: 0.4923916	best: 0.4923916 (3200)	total: 2m 20s	remaining: 4m 14s
3400:	learn: 0.4808349	test: 0.4910266	best: 0.4910266 (3400)	total: 2m 28s	remaining: 4m 4s
3600:	learn: 0.4786815	test: 0.4900211	best: 0.4900211 (3600)	total: 2m 36s	remaining: 3m 55s
3800:	learn: 0.4765873	test: 0.4891687	best: 0.4891687 (3800)	total: 2m 45s	remaining: 3m 45s
4000:	learn: 0.4746466	test: 0.4884166	best: 0.4884166 (4000)	total: 2m 53s	remaining: 3m 37s
4200:	learn: 0.4727689	test: 0.4877134	best: 0.4877134 (4200)	total: 3m 1s	remaining: 3m 27s
4400:	learn: 0.4711919	test: 0.4873153	best: 0.4873101 (4397)	total: 3m 10s	remaining: 3m 18s
4600:	learn: 0.4697039	test: 0.4868219	best: 0.4868190 (4595)	total: 3m 18s	remaining: 3m 9s
4800:	learn: 0.4682294	test: 0.4864008	best: 0.4863952 (4798)	total: 3m 27s	remaining: 3m 1s
5000:	learn: 0.4667297	test: 0.4859959	best: 0.4859959 (5000)	total: 3m 35s	remaining: 2m 52s
5200:	learn: 0.4651569	test: 0.4855926	best: 0.4855926 (5200)	total: 3m 43s	remaining: 2m 43s
5400:	learn: 0.4636121	test: 0.4853511	best: 0.4853511 (5400)	total: 3m 52s	remaining: 2m 35s
5600:	learn: 0.4620636	test: 0.4850813	best: 0.4850758 (5596)	total: 4m 1s	remaining: 2m 26s
5800:	learn: 0.4605514	test: 0.4849204	best: 0.4849140 (5788)	total: 4m 9s	remaining: 2m 17s
6000:	learn: 0.4591057	test: 0.4847769	best: 0.4847750 (5997)	total: 4m 17s	remaining: 2m 8s
6200:	learn: 0.4578943	test: 0.4847669	best: 0.4847531 (6144)	total: 4m 26s	remaining: 2m
6400:	learn: 0.4567455	test: 0.4847794	best: 0.4847531 (6144)	total: 4m 34s	remaining: 1m 51s
Stopped by overfitting detector  (300 iterations wait)

bestTest = 0.4847530661
bestIteration = 6144

Shrink model to first 6145 iterations.
Training Folds: 100%|██████████| 5/5 [25:01<00:00, 300.28s/it]
Fold 5 - Train RMSE: 0.4582, Validation RMSE: 0.4848
Mean Train F1 --> 0.4594
Mean Validation F1 ---> 0.5021
```

### RMSE
```python
model = CatBoostRegressor(
    iterations=9000,           # 延长迭代次数
    learning_rate=0.02,        # 更慢收敛
    depth=7,                   # 降低深度，延长训练周期
    l2_leaf_reg=6,             # 略加正则化
    bagging_temperature=1.0,   # 保持多样性
    random_strength=1.0,       
    border_count=254,
    boosting_type='Plain',
    loss_function='RMSE',
    eval_metric='RMSE',
    random_seed=42,
    od_type='Iter',
    od_wait=300,               # 延长早停等待，保证充分训练
    verbose=200
)  
```  

实验日志  
```plaintext
(19550, 141) (5664, 141)
time          0
real_power    0
hour_sin      0
hour_cos      0
month_sin     0
             ..
wd_cos_-1     0
wd_cos_1      1
wd_cos_2      2
wd_cos_3      3
wd_cos_4      4
Length: 141, dtype: int64
time             0
predict_power    0
hour_sin         0
hour_cos         0
month_sin        0
                ..
wd_cos_-1        1
wd_cos_1         0
wd_cos_2         0
wd_cos_3         0
wd_cos_4         0
Length: 141, dtype: int64
Training Folds:   0%|          | 0/5 [00:00<?, ?it/s]
0:	learn: 44.8624666	test: 46.4621228	best: 46.4621228 (0)	total: 121ms	remaining: 18m 11s
200:	learn: 22.3099016	test: 25.6438490	best: 25.6438490 (200)	total: 7.29s	remaining: 5m 19s
400:	learn: 20.1246936	test: 25.0409601	best: 25.0407876 (399)	total: 13.7s	remaining: 4m 53s
600:	learn: 18.6113658	test: 24.9430821	best: 24.9409053 (590)	total: 20s	remaining: 4m 39s
800:	learn: 17.3451652	test: 24.9327829	best: 24.8900086 (725)	total: 26.4s	remaining: 4m 29s
1000:	learn: 16.2197608	test: 24.9513715	best: 24.8900086 (725)	total: 32.8s	remaining: 4m 21s
Training Folds:  20%|██        | 1/5 [00:34<02:17, 34.26s/it]
Stopped by overfitting detector  (300 iterations wait)

bestTest = 24.89000862
bestIteration = 725

Shrink model to first 726 iterations.
Fold 1 - Train RMSE: 0.5555, Validation RMSE: 0.6992
0:	learn: 44.8217904	test: 46.5370954	best: 46.5370954 (0)	total: 73.8ms	remaining: 11m 3s
200:	learn: 21.6547918	test: 27.3721570	best: 27.3643776 (198)	total: 6.96s	remaining: 5m 4s
400:	learn: 19.3707253	test: 27.5604688	best: 27.3544539 (212)	total: 13.3s	remaining: 4m 46s
Training Folds:  40%|████      | 2/5 [00:51<01:12, 24.27s/it]
Stopped by overfitting detector  (300 iterations wait)

bestTest = 27.35445387
bestIteration = 212

Shrink model to first 213 iterations.
Fold 2 - Train RMSE: 0.6457, Validation RMSE: 0.7481
0:	learn: 46.3472691	test: 40.1277062	best: 40.1277062 (0)	total: 42.3ms	remaining: 6m 20s
200:	learn: 22.0932719	test: 24.8804747	best: 24.8803516 (199)	total: 6.64s	remaining: 4m 50s
400:	learn: 19.8316993	test: 24.8924224	best: 24.8206982 (274)	total: 13s	remaining: 4m 39s
Training Folds:  60%|██████    | 3/5 [01:10<00:44, 22.06s/it]
Stopped by overfitting detector  (300 iterations wait)

bestTest = 24.82069821
bestIteration = 274

Shrink model to first 275 iterations.
Fold 3 - Train RMSE: 0.6399, Validation RMSE: 0.7477
0:	learn: 46.0360737	test: 41.6654083	best: 41.6654083 (0)	total: 37.2ms	remaining: 5m 34s
200:	learn: 22.3618771	test: 25.9594180	best: 25.9551567 (197)	total: 6.54s	remaining: 4m 46s
400:	learn: 20.1500183	test: 25.8795016	best: 25.7799865 (276)	total: 12.9s	remaining: 4m 37s
Training Folds:  80%|████████  | 4/5 [01:29<00:20, 20.79s/it]
Stopped by overfitting detector  (300 iterations wait)

bestTest = 25.77998647
bestIteration = 276

Shrink model to first 277 iterations.
Fold 4 - Train RMSE: 0.6397, Validation RMSE: 0.9624
0:	learn: 43.5357722	test: 51.5298711	best: 51.5298711 (0)	total: 35.1ms	remaining: 5m 15s
200:	learn: 21.9099250	test: 27.1525053	best: 27.1525053 (200)	total: 6.55s	remaining: 4m 46s
400:	learn: 19.8919409	test: 26.6872878	best: 26.6871069 (395)	total: 13.6s	remaining: 4m 52s
600:	learn: 18.3993070	test: 26.5458742	best: 26.5458742 (600)	total: 20s	remaining: 4m 38s
800:	learn: 17.0531057	test: 26.5299043	best: 26.5167221 (731)	total: 26.3s	remaining: 4m 29s
1000:	learn: 15.8779983	test: 26.5033197	best: 26.4994335 (912)	total: 32.7s	remaining: 4m 21s
1200:	learn: 14.8945726	test: 26.5452720	best: 26.4994335 (912)	total: 39s	remaining: 4m 13s
Training Folds: 100%|██████████| 5/5 [02:09<00:00, 25.93s/it]
Stopped by overfitting detector  (300 iterations wait)

bestTest = 26.49943352
bestIteration = 912

Shrink model to first 913 iterations.
Fold 5 - Train RMSE: 0.5195, Validation RMSE: 0.6661
Mean Train F1 --> 0.6001
Mean Validation F1 ---> 0.7647  
```

### 总结  
通过自定义CatBoost的损失函数和评估指标（从RMSE-> RMSPE）,在五折交叉验证，测试集RMSPE从0.7647提高到0.5021。因此根据不同任务的需求，选择合适的损失函数和评估指标是非常重要的。